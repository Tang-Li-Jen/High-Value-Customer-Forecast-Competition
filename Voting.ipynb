{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score, f1_score, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['submission_0698.csv',\n",
       " 'submission_06988.csv',\n",
       " '.DS_Store',\n",
       " 'submission_06989.csv',\n",
       " 'submission_ensem.csv',\n",
       " 'Untitled.ipynb',\n",
       " 'submission.csv',\n",
       " 'modeling.ipynb',\n",
       " 'README.md',\n",
       " 'submission_069859.csv',\n",
       " 'submission_067.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'submission_069812.csv',\n",
       " '.git',\n",
       " 'submission_0685.csv',\n",
       " 'data',\n",
       " 'submission_0695.csv',\n",
       " 'Voting.ipynb',\n",
       " 'submission_0683.csv']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "source": [
    "## Voting Ensembles make the final result\n",
    "We combined the resulted labels from each stage (different input features to the lightgbm model) to decide the final possibilities, which makes our prediction more robust."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results from each training stage\n",
    "#sub1 = pd.read_csv('submission_069859.csv')\n",
    "#sub2 = pd.read_csv('submission_069812.csv')\n",
    "sub3 = pd.read_csv('submission_06989.csv')\n",
    "sub4 = pd.read_csv('submission_06988.csv')\n",
    "sub5 = pd.read_csv('submission_0699.csv')\n",
    "sub6 = pd.read_csv('submission_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the result into a dataset\n",
    "df_all = pd.concat([sub3,sub4,sub5,sub6])\n",
    "\n",
    "# Average the labels to get `soft voting` result\n",
    "pred = df_all.groupby('userid',as_index=False).label.mean()\n",
    "pred.to_csv('submission_ensem.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}