{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the packages\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score, f1_score, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from functools import reduce\n",
    "import os"
   ]
  },
  {
   "source": [
    "## Import the source dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the data folder path\n",
    "folder_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['feature_v5.csv',\n",
       " 'feature_v4.csv',\n",
       " 'feature_v3.csv',\n",
       " '.DS_Store',\n",
       " 'total_vairables.csv',\n",
       " 'submission.csv',\n",
       " 'user_info.csv',\n",
       " 'purchase_detail.csv',\n",
       " 'login.csv',\n",
       " 'month_amount.csv',\n",
       " 'user_label_train.csv',\n",
       " 'rfm_features.csv',\n",
       " 'growth_features.csv',\n",
       " 'source_data.zip']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Peek what is in the folder \n",
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the source data\n",
    "df_train = pd.read_csv(os.path.join(folder_path, 'user_label_train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(folder_path, 'submission.csv'))\n",
    "df_user_info = pd.read_csv(os.path.join(folder_path, 'user_info.csv'))\n",
    "df_login = pd.read_csv(os.path.join(folder_path, 'login.csv'))\n",
    "df_purchase_detail = pd.read_csv(os.path.join(folder_path, 'purchase_detail.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the auxilary dataset created from feature engineering\n",
    "#df_month = pd.read_csv(os.path.join(folder_path, 'month_amount.csv')) #Replaced by df_monthly_buy_sum_pivot\n",
    "df_feature_v3 = pd.read_csv(os.path.join(folder_path, 'feature_v3.csv'))\n",
    "df_feature_v4 = pd.read_csv(os.path.join(folder_path, 'feature_v4.csv'))\n",
    "df_feature_v5 = pd.read_csv(os.path.join(folder_path, 'feature_v5.csv'))\n",
    "df_growth_features = pd.read_csv(os.path.join(folder_path, 'growth_features.csv'))\n",
    "df_rfm_features = pd.read_csv(os.path.join(folder_path, 'rfm_features.csv'))"
   ]
  },
  {
   "source": [
    "## Know Your Data: Exploratory Data Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0.658207\n",
       "1    0.341793\n",
       "Name: label, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_train['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the number of train: 426832\nthe number of test: 75325\n"
     ]
    }
   ],
   "source": [
    "print('the number of train: {}'.format(len(df_train)))\n",
    "print('the number of test: {}'.format(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 426832 entries, 0 to 426831\nData columns (total 2 columns):\n #   Column  Non-Null Count   Dtype\n---  ------  --------------   -----\n 0   userid  426832 non-null  int64\n 1   label   426832 non-null  int64\ndtypes: int64(2)\nmemory usage: 6.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Peek user_label_train\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 502157 entries, 0 to 502156\nData columns (total 5 columns):\n #   Column       Non-Null Count   Dtype  \n---  ------       --------------   -----  \n 0   userid       502157 non-null  int64  \n 1   gender       502122 non-null  float64\n 2   is_seller    502157 non-null  int64  \n 3   birth_year   277496 non-null  float64\n 4   enroll_time  502157 non-null  object \ndtypes: float64(2), int64(2), object(1)\nmemory usage: 19.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Peek user_info.csv\n",
    "df_user_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50705586 entries, 0 to 50705585\nData columns (total 3 columns):\n #   Column       Dtype \n---  ------       ----- \n 0   userid       int64 \n 1   date         object\n 2   login_times  int64 \ndtypes: int64(2), object(1)\nmemory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "# Peek login.csv\n",
    "df_login.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7792956 entries, 0 to 7792955\nData columns (total 5 columns):\n #   Column            Dtype \n---  ------            ----- \n 0   userid            int64 \n 1   grass_date        object\n 2   order_count       int64 \n 3   total_amount      int64 \n 4   category_encoded  int64 \ndtypes: int64(4), object(1)\nmemory usage: 297.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Peek purchase_detail.csv\n",
    "df_purchase_detail.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 75325 entries, 0 to 75324\nData columns (total 1 columns):\n #   Column  Non-Null Count  Dtype\n---  ------  --------------  -----\n 0   userid  75325 non-null  int64\ndtypes: int64(1)\nmemory usage: 588.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Peek submission.csv\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The number of train: 426832\nThe number of test: 75325\n"
     ]
    }
   ],
   "source": [
    "# Prepare for the train and test dataset with synchronous pre-process\n",
    "df_train = pd.merge(df_train, df_user_info, on='userid', how='inner')\n",
    "df_test = pd.merge(df_test, df_user_info, on='userid', how='inner')\n",
    "\n",
    "print('The number of train: {}'.format(len(df_train)))\n",
    "print('The number of test: {}'.format(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the age from the birth_year\n",
    "df_train['age'] = 2020 - df_train.birth_year\n",
    "df_test['age'] = 2020 - df_test.birth_year\n",
    "\n",
    "# Process the enroll time to `pd.datetime` type\n",
    "df_train['enroll_time'] = pd.to_datetime(df_train['enroll_time'])\n",
    "df_test['enroll_time'] = pd.to_datetime(df_test['enroll_time'])\n",
    "\n",
    "# Process the account lifetime to df_train and df_test respectively\n",
    "df_train['lifetime'] = pd.to_datetime('2020-07-31') - pd.to_datetime(df_train['enroll_time'])\n",
    "df_train.lifetime = df_train.lifetime.astype('timedelta64[D]')\n",
    "\n",
    "df_test['lifetime'] = pd.to_datetime('2020-07-31') - pd.to_datetime(df_test['enroll_time'])\n",
    "df_test.lifetime = df_test.lifetime.astype('timedelta64[D]')"
   ]
  },
  {
   "source": [
    "### - Preliminarily Process the df_login (login.csv)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the login log to count total login times, min/max login times for a day, std and mean for overall login times\n",
    "df_login_feature = df_login.groupby('userid').agg({'login_times':['sum', 'min', 'max', 'std', 'mean']})\n",
    "df_login_feature.columns = [\"_\".join(x) for x in df_login_feature.columns.ravel()] #automatically add column names"
   ]
  },
  {
   "source": [
    "### - Preliminarily Process the df_purchase_detail (purchase_detail.csv)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         userid  grass_date  order_count  total_amount  category_encoded\n",
       "0        295790  2020-05-13            4             4                 8\n",
       "2928017  295790  2020-06-11           27            48                 8\n",
       "2931480  295790  2020-03-18            2             2                 6\n",
       "2934264  295790  2020-04-22            3             4                 6\n",
       "2938794  295790  2020-06-11            1             4                15\n",
       "2939318  295790  2020-06-29            2             2                 9\n",
       "2940983  295790  2020-06-29            1             1                 6\n",
       "2955053  295790  2020-07-29            1             1                 6\n",
       "2959250  295790  2020-03-30            1             1                22\n",
       "2960153  295790  2020-06-11            2             4                22\n",
       "2966540  295790  2020-04-22            1             1                 3\n",
       "2966972  295790  2020-03-18            1             1                 8\n",
       "2977539  295790  2020-03-30           22            30                 8\n",
       "2980470  295790  2020-05-20            1             1                 8\n",
       "2983956  295790  2020-07-13            1            30                 6\n",
       "2989137  295790  2020-05-26            1             2                 6\n",
       "3008126  295790  2020-07-29            1             1                 9\n",
       "3008308  295790  2020-04-25            2             2                15\n",
       "3013632  295790  2020-05-08            4             4                23\n",
       "3016938  295790  2020-03-30            5             5                23\n",
       "3018213  295790  2020-03-30            2             2                15\n",
       "3022649  295790  2020-05-11            1             2                 8\n",
       "3029038  295790  2020-05-08            3             3                15\n",
       "3043702  295790  2020-03-30            1             1                14\n",
       "4082934  295790  2020-07-31            2             2                 8\n",
       "4083929  295790  2020-04-21            5             5                23"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userid</th>\n      <th>grass_date</th>\n      <th>order_count</th>\n      <th>total_amount</th>\n      <th>category_encoded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>295790</td>\n      <td>2020-05-13</td>\n      <td>4</td>\n      <td>4</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2928017</th>\n      <td>295790</td>\n      <td>2020-06-11</td>\n      <td>27</td>\n      <td>48</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2931480</th>\n      <td>295790</td>\n      <td>2020-03-18</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2934264</th>\n      <td>295790</td>\n      <td>2020-04-22</td>\n      <td>3</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2938794</th>\n      <td>295790</td>\n      <td>2020-06-11</td>\n      <td>1</td>\n      <td>4</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2939318</th>\n      <td>295790</td>\n      <td>2020-06-29</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2940983</th>\n      <td>295790</td>\n      <td>2020-06-29</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2955053</th>\n      <td>295790</td>\n      <td>2020-07-29</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2959250</th>\n      <td>295790</td>\n      <td>2020-03-30</td>\n      <td>1</td>\n      <td>1</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2960153</th>\n      <td>295790</td>\n      <td>2020-06-11</td>\n      <td>2</td>\n      <td>4</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2966540</th>\n      <td>295790</td>\n      <td>2020-04-22</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2966972</th>\n      <td>295790</td>\n      <td>2020-03-18</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2977539</th>\n      <td>295790</td>\n      <td>2020-03-30</td>\n      <td>22</td>\n      <td>30</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2980470</th>\n      <td>295790</td>\n      <td>2020-05-20</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2983956</th>\n      <td>295790</td>\n      <td>2020-07-13</td>\n      <td>1</td>\n      <td>30</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2989137</th>\n      <td>295790</td>\n      <td>2020-05-26</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3008126</th>\n      <td>295790</td>\n      <td>2020-07-29</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3008308</th>\n      <td>295790</td>\n      <td>2020-04-25</td>\n      <td>2</td>\n      <td>2</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3013632</th>\n      <td>295790</td>\n      <td>2020-05-08</td>\n      <td>4</td>\n      <td>4</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>3016938</th>\n      <td>295790</td>\n      <td>2020-03-30</td>\n      <td>5</td>\n      <td>5</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>3018213</th>\n      <td>295790</td>\n      <td>2020-03-30</td>\n      <td>2</td>\n      <td>2</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3022649</th>\n      <td>295790</td>\n      <td>2020-05-11</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3029038</th>\n      <td>295790</td>\n      <td>2020-05-08</td>\n      <td>3</td>\n      <td>3</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3043702</th>\n      <td>295790</td>\n      <td>2020-03-30</td>\n      <td>1</td>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4082934</th>\n      <td>295790</td>\n      <td>2020-07-31</td>\n      <td>2</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4083929</th>\n      <td>295790</td>\n      <td>2020-04-21</td>\n      <td>5</td>\n      <td>5</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# See the purchase detail of a certain user and know how data sorted\n",
    "df_purchase_detail[df_purchase_detail.userid == 295790]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the field `grass_date` to be datatime type \n",
    "df_purchase_detail['grass_date'] = pd.to_datetime(df_purchase_detail.grass_date)\n",
    "\n",
    "# Sort the purchase detail by userid and purchase date \n",
    "df_purchase_detail = df_purchase_detail.sort_values(['userid', 'grass_date'], ascending=[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        dt_diff_sum  dt_diff_min  dt_diff_max  dt_diff_std  dt_diff_mean\n",
       "userid                                                                  \n",
       "1             174.0          3.0         50.0    17.705931     19.333333\n",
       "2             147.0          1.0         28.0     8.473942     10.500000\n",
       "3              94.0          3.0         41.0    14.854853     15.666667\n",
       "4             170.0          1.0         16.0     4.220911      5.666667\n",
       "5             171.0          1.0         18.0     3.603718      3.886364"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dt_diff_sum</th>\n      <th>dt_diff_min</th>\n      <th>dt_diff_max</th>\n      <th>dt_diff_std</th>\n      <th>dt_diff_mean</th>\n    </tr>\n    <tr>\n      <th>userid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>174.0</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>17.705931</td>\n      <td>19.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>147.0</td>\n      <td>1.0</td>\n      <td>28.0</td>\n      <td>8.473942</td>\n      <td>10.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>94.0</td>\n      <td>3.0</td>\n      <td>41.0</td>\n      <td>14.854853</td>\n      <td>15.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>170.0</td>\n      <td>1.0</td>\n      <td>16.0</td>\n      <td>4.220911</td>\n      <td>5.666667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>171.0</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>3.603718</td>\n      <td>3.886364</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Process the purchase time to see the freqency of a user's purchasement\n",
    "df_dt = df_purchase_detail[['userid','grass_date']].drop_duplicates()\n",
    "df_dt['dt_diff'] = df_dt.groupby('userid')['grass_date'].diff().astype('timedelta64[D]')\n",
    "df_purchase_dt_diff = df_dt.groupby('userid').agg({'dt_diff':['sum', 'min', 'max', 'std', 'mean']})\n",
    "df_purchase_dt_diff.columns = [\"_\".join(x) for x in df_purchase_dt_diff.columns.ravel()]\n",
    "\n",
    "df_purchase_dt_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        month_2_sum_pivot  month_3_sum_pivot  month_4_sum_pivot  \\\n",
       "userid                                                            \n",
       "1                   170.0                NaN               29.0   \n",
       "2                     NaN               10.0                8.0   \n",
       "3                     NaN                2.0                2.0   \n",
       "4                    13.0                5.0               12.0   \n",
       "5                    14.0               27.0             2597.0   \n",
       "\n",
       "        month_5_sum_pivot  month_6_sum_pivot  month_7_sum_pivot  \n",
       "userid                                                           \n",
       "1                     2.0                5.0               40.0  \n",
       "2                    19.0               10.0               12.0  \n",
       "3                     3.0                7.0                NaN  \n",
       "4                    12.0               25.0               15.0  \n",
       "5                     8.0               20.0               68.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month_2_sum_pivot</th>\n      <th>month_3_sum_pivot</th>\n      <th>month_4_sum_pivot</th>\n      <th>month_5_sum_pivot</th>\n      <th>month_6_sum_pivot</th>\n      <th>month_7_sum_pivot</th>\n    </tr>\n    <tr>\n      <th>userid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>170.0</td>\n      <td>NaN</td>\n      <td>29.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>8.0</td>\n      <td>19.0</td>\n      <td>10.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>25.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.0</td>\n      <td>27.0</td>\n      <td>2597.0</td>\n      <td>8.0</td>\n      <td>20.0</td>\n      <td>68.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Calculate the monthly purchase summary for each user (Replace original df_month)\n",
    "df_purchase_detail['month'] = df_purchase_detail.grass_date.dt.month\n",
    "\n",
    "df_monthly_buy = df_purchase_detail.groupby(['userid', 'month']).agg({'order_count':['sum', 'mean'], 'total_amount':['sum', 'mean']})\n",
    "df_monthly_buy.columns = [\"_\".join(x) for x in df_monthly_buy.columns.ravel()]\n",
    "\n",
    "# Transform the monthly summary into pivot table to easily merge back to df_train and df_train\n",
    "df_monthly_buy_sum_pivot = pd.pivot_table(df_monthly_buy, index='userid', columns='month', values='total_amount_sum') #.to_csv('month_amount.csv')\n",
    "df_monthly_buy_sum_pivot.columns = [ f'month_{x}_sum_pivot' for x in df_monthly_buy_sum_pivot.columns.ravel()]\n",
    "\n",
    "df_monthly_buy_avg_pivot = pd.pivot_table(df_monthly_buy, index='userid', columns='month', values='total_amount_mean') #.to_csv('month_total_amount_mean.csv')\n",
    "df_monthly_buy_avg_pivot.columns = [ f'month_{x}_avg_pivot' for x in df_monthly_buy_avg_pivot.columns.ravel()]\n",
    "\n",
    "df_monthly_buy_sum_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total n purchase days of each user \n",
    "df_purchase_ndays = df_purchase_detail.groupby('userid')['grass_date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average purchase amount per order of each user\n",
    "df_purchase_detail['amount_per_order'] = df_purchase_detail.total_amount / df_purchase_detail.order_count\n",
    "df_purchase_amount_per_order = df_purchase_detail.groupby('userid').agg({'amount_per_order':['sum', 'min', 'max', 'std','mean']})\n",
    "df_purchase_amount_per_order.columns = [\"_\".join(x) for x in df_purchase_amount_per_order.columns.ravel()]\n",
    "\n",
    "# Calculate the statistics of the purchase of each user as new features\n",
    "df_purchase_detail_feature = df_purchase_detail.groupby('userid').agg({'order_count':['sum', 'min', 'max', 'std', 'mean'],\n",
    "                                                                       'total_amount':['sum', 'min', 'max', 'std','mean']})\n",
    "df_purchase_detail_feature.columns = [\"_\".join(x) for x in df_purchase_detail_feature.columns.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total purchase amount of each category for each user\n",
    "df_category_count = df_purchase_detail.groupby(['userid','category_encoded'], as_index=False)['total_amount'].sum()\n",
    "df_category_pivot = pd.pivot_table(df_category_count, index='userid', \n",
    "                                                      columns='category_encoded',\n",
    "                                                      values='total_amount')\n",
    "df_category_pivot = df_category_pivot.fillna(0)\n",
    "df_category_pivot.columns = ['category_' + str(x) for x in df_category_pivot.columns]"
   ]
  },
  {
   "source": [
    "### - Apply RFM Model to synethesize the features (WIP)\n",
    "RFM stands for *Receency*, *Frequency*, and *Monetary*. But we don't have the price for each product category `category_encoded`, we then use total amount to calculate for the *Monetary* feature. Also, we utilized `login.csv` to calculate users' login behavior -- *Receency* and *Frequency*."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   userid        date  login_times\n",
       "0  161097  2020-07-29            2\n",
       "1  243570  2020-07-29            2\n",
       "2  355497  2020-07-29            4\n",
       "3  167925  2020-07-29            1\n",
       "4  504766  2020-07-29            1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userid</th>\n      <th>date</th>\n      <th>login_times</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>161097</td>\n      <td>2020-07-29</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>243570</td>\n      <td>2020-07-29</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>355497</td>\n      <td>2020-07-29</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>167925</td>\n      <td>2020-07-29</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>504766</td>\n      <td>2020-07-29</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df_login.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login Recency\n",
    "#df_login_recency = pd.DataFrame(df_login.groupby('userid').max()['date'])\n",
    "#df_login_recency['login_recency'] = pd.to_datetime('2020-07-31')- pd.to_datetime(df_login_recency['date']) # the end date of this dataset is 2020/07/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (WIP) Other RFM features are produced in R code, which will be transformed to python code in the future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the desired features from the dataset created from R code\n",
    "df_rfm_features = df_rfm_features[['userid', 'DistinctDay', 'DistinctDayIn90days', 'DistinctDayIn60days',\n",
    "       'DistinctDayIn30days', 'DistinctDayIn14days', 'DistinctDayIn7days',\n",
    "       'DistinctDayIn3days', 'FreqIn90days', 'FreqIn60days',\n",
    "       'FreqIn14days', 'FreqIn3days', 'FreqIn7days', 'rececny']]"
   ]
  },
  {
   "source": [
    "## Integrate all systhesized featurs into both the `df_train` and `df_test` datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge synthesized features back into df_train and df_test\n",
    "df_list = [df_login_feature, df_purchase_dt_diff, df_feature_v3, df_feature_v4, df_feature_v5, df_monthly_buy_sum_pivot, df_purchase_ndays, \n",
    "           df_purchase_detail_feature, df_purchase_amount_per_order, df_growth_features, df_rfm_features, df_category_pivot] #remove `df_month` and add `df_monthly_buy_sum_pivot`\n",
    "\n",
    "# Applied `reduce` function to merge the orginal df_train/df_test and created features\n",
    "df_train = reduce(lambda left, right: pd.merge(left, right, on='userid', how='inner'), [df_train, *df_list])\n",
    "df_test = reduce(lambda left, right: pd.merge(left, right, on='userid', how='inner'), [df_test, *df_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['userid', 'label', 'gender', 'is_seller', 'birth_year', 'enroll_time',\n",
       "       'age', 'lifetime', 'login_times_sum', 'login_times_min',\n",
       "       'login_times_max', 'login_times_std', 'login_times_mean', 'dt_diff_sum',\n",
       "       'dt_diff_min', 'dt_diff_max', 'dt_diff_std', 'dt_diff_mean',\n",
       "       'AvgMoMOrderCnt', 'AvgMoMTotCnt', 'OrderCntIn90days', 'TotCntIn90days',\n",
       "       'OrderCntIn60days', 'TotCntIn60days', 'OrderCntIn30days',\n",
       "       'TotCntIn30days', 'OrderCntIn14days', 'TotCntIn14days',\n",
       "       'OrderCntIn7days', 'TotCntIn7days', 'OrderCntIn3days', 'TotCntIn3days',\n",
       "       'BuyRececny', 'DistinctCategory', 'GoodBuyer', 'month_2_sum_pivot',\n",
       "       'month_3_sum_pivot', 'month_4_sum_pivot', 'month_5_sum_pivot',\n",
       "       'month_6_sum_pivot', 'month_7_sum_pivot', 'grass_date',\n",
       "       'order_count_sum', 'order_count_min', 'order_count_max',\n",
       "       'order_count_std', 'order_count_mean', 'total_amount_sum',\n",
       "       'total_amount_min', 'total_amount_max', 'total_amount_std',\n",
       "       'total_amount_mean', 'amount_per_order_sum', 'amount_per_order_min',\n",
       "       'amount_per_order_max', 'amount_per_order_std', 'amount_per_order_mean',\n",
       "       'avgFreqMoM', 'DistinctDay', 'DistinctDayIn90days',\n",
       "       'DistinctDayIn60days', 'DistinctDayIn30days', 'DistinctDayIn14days',\n",
       "       'DistinctDayIn7days', 'DistinctDayIn3days', 'FreqIn90days',\n",
       "       'FreqIn60days', 'FreqIn14days', 'FreqIn3days', 'FreqIn7days', 'rececny',\n",
       "       'category_1', 'category_2', 'category_3', 'category_4', 'category_5',\n",
       "       'category_6', 'category_7', 'category_8', 'category_9', 'category_10',\n",
       "       'category_11', 'category_12', 'category_13', 'category_14',\n",
       "       'category_15', 'category_16', 'category_17', 'category_18',\n",
       "       'category_19', 'category_20', 'category_21', 'category_22',\n",
       "       'category_23'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# List out the current sythesized features on train and test dataset\n",
    "df_train.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test datasets\n",
    "df_tr, df_val = train_test_split(df_train, stratify = df_train['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "# List out the features for traing\n",
    "features = ['gender', 'is_seller', 'birth_year', 'age', 'lifetime', \n",
    "            'login_times_sum', 'login_times_min', 'login_times_max', \n",
    "            'login_times_std', 'login_times_mean', 'dt_diff_sum',\n",
    "            'dt_diff_min', 'dt_diff_max', 'dt_diff_std', 'dt_diff_mean',\n",
    "            'AvgMoMOrderCnt', 'AvgMoMTotCnt', 'OrderCntIn90days', 'TotCntIn90days',\n",
    "            'OrderCntIn60days', 'TotCntIn60days', 'OrderCntIn30days',\n",
    "            'TotCntIn30days', 'OrderCntIn14days', 'TotCntIn14days',\n",
    "            'OrderCntIn7days', 'TotCntIn7days', 'OrderCntIn3days', 'TotCntIn3days',\n",
    "            'BuyRececny', 'DistinctCategory', 'GoodBuyer', 'month_2_sum_pivot',\n",
    "            'month_3_sum_pivot', 'month_4_sum_pivot', 'month_5_sum_pivot',\n",
    "            'month_6_sum_pivot', 'month_7_sum_pivot', 'grass_date',\n",
    "            'order_count_sum', 'order_count_min', 'order_count_max',\n",
    "            'order_count_std', 'order_count_mean', 'total_amount_sum',\n",
    "            'total_amount_min', 'total_amount_max', 'total_amount_std',\n",
    "            'total_amount_mean', 'amount_per_order_sum', 'amount_per_order_min',\n",
    "            'amount_per_order_max', 'amount_per_order_std', 'amount_per_order_mean',\n",
    "            'avgFreqMoM', 'DistinctDay', 'DistinctDayIn90days',\n",
    "            'DistinctDayIn60days', 'DistinctDayIn30days', 'DistinctDayIn14days',\n",
    "            'DistinctDayIn7days', 'DistinctDayIn3days', 'FreqIn90days',\n",
    "            'FreqIn60days', 'FreqIn14days', 'FreqIn3days', 'FreqIn7days', 'rececny',\n",
    "            'category_1', 'category_2', 'category_3', 'category_4', 'category_5',\n",
    "            'category_6', 'category_7', 'category_8', 'category_9', 'category_10',\n",
    "            'category_11', 'category_12', 'category_13', 'category_14',\n",
    "            'category_15', 'category_16', 'category_17', 'category_18',\n",
    "            'category_19', 'category_20', 'category_21', 'category_22',\n",
    "            'category_23']\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and validation sets\n",
    "tr_X = df_tr[features].values\n",
    "tr_y = df_tr['label']\n",
    "\n",
    "val_X = df_val[features].values\n",
    "val_y = df_val['label']\n",
    "\n",
    "te_X = df_test[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets into lgd.Dataset format\n",
    "lgtrain = lgb.Dataset(tr_X, tr_y)\n",
    "lgvalid = lgb.Dataset(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "params = {\n",
    "          \"objective\" : \"binary\",\n",
    "          \"num_leaves\" : 30,\n",
    "          \"max_depth\": -1,\n",
    "          \"bagging_fraction\" : 0.8,  # subsample\n",
    "          \"feature_fraction\" : 0.8,  # colsample_bytree\n",
    "          \"bagging_freq\" : 5,        # subsample_freq\n",
    "          \"bagging_seed\" : 2018,\n",
    "          \"num_threads\":4,\n",
    "          'lambda_l1': 0.9, \n",
    "          'lambda_l2': 0.5, \n",
    "          'learning_rate': 0.01, \n",
    "          'metric': 'AUC',\n",
    "          'is_unbalance': False,\n",
    "          \"verbosity\" : -1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttrain's auc: 0.685575\tvalidation's auc: 0.681029\n",
      "[100]\ttrain's auc: 0.688563\tvalidation's auc: 0.683216\n",
      "[150]\ttrain's auc: 0.691162\tvalidation's auc: 0.685512\n",
      "[200]\ttrain's auc: 0.693754\tvalidation's auc: 0.687768\n",
      "[250]\ttrain's auc: 0.696127\tvalidation's auc: 0.68979\n",
      "[300]\ttrain's auc: 0.698264\tvalidation's auc: 0.691498\n",
      "[350]\ttrain's auc: 0.700111\tvalidation's auc: 0.692901\n",
      "[400]\ttrain's auc: 0.701737\tvalidation's auc: 0.694049\n",
      "[450]\ttrain's auc: 0.703116\tvalidation's auc: 0.694895\n",
      "[500]\ttrain's auc: 0.704414\tvalidation's auc: 0.695697\n",
      "[550]\ttrain's auc: 0.705569\tvalidation's auc: 0.696299\n",
      "[600]\ttrain's auc: 0.706619\tvalidation's auc: 0.696796\n",
      "[650]\ttrain's auc: 0.707621\tvalidation's auc: 0.697275\n",
      "[700]\ttrain's auc: 0.708579\tvalidation's auc: 0.697684\n",
      "[750]\ttrain's auc: 0.70947\tvalidation's auc: 0.698026\n",
      "[800]\ttrain's auc: 0.710307\tvalidation's auc: 0.698264\n",
      "[850]\ttrain's auc: 0.711184\tvalidation's auc: 0.698506\n",
      "[900]\ttrain's auc: 0.711971\tvalidation's auc: 0.698703\n",
      "[950]\ttrain's auc: 0.712736\tvalidation's auc: 0.698863\n",
      "[1000]\ttrain's auc: 0.713449\tvalidation's auc: 0.699042\n",
      "[1050]\ttrain's auc: 0.714184\tvalidation's auc: 0.699175\n",
      "[1100]\ttrain's auc: 0.714879\tvalidation's auc: 0.699286\n",
      "[1150]\ttrain's auc: 0.715585\tvalidation's auc: 0.699387\n",
      "[1200]\ttrain's auc: 0.71629\tvalidation's auc: 0.699506\n",
      "[1250]\ttrain's auc: 0.717002\tvalidation's auc: 0.699597\n",
      "[1300]\ttrain's auc: 0.717667\tvalidation's auc: 0.699687\n",
      "[1350]\ttrain's auc: 0.718372\tvalidation's auc: 0.699757\n",
      "[1400]\ttrain's auc: 0.719045\tvalidation's auc: 0.699844\n",
      "[1450]\ttrain's auc: 0.719702\tvalidation's auc: 0.699903\n",
      "[1500]\ttrain's auc: 0.720347\tvalidation's auc: 0.699993\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttrain's auc: 0.720347\tvalidation's auc: 0.699993\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "evals_result = {}\n",
    "\n",
    "clf = lgb.train(params,\n",
    "                lgtrain,\n",
    "                1500,\n",
    "                valid_sets = [lgvalid, lgtrain],\n",
    "                valid_names = ['validation', 'train'],\n",
    "#               feval=lgb_fbeta_score,\n",
    "                evals_result = evals_result,\n",
    "                early_stopping_rounds = 200,\n",
    "                verbose_eval = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the unknown label by the trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedict the labels\n",
    "pred_test = clf.predict(te_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the predict labels to `submission.csv`\n",
    "sub = pd.read_csv(os.path.join(folder_path, 'submission.csv'))\n",
    "sub['label'] = pred_test\n",
    "\n",
    "sub.to_csv('submission_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}